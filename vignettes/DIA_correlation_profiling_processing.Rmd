---
title: "Correlation Profiling Proteomics with DIA-NN: Part 1 - Data Processing and QC"
author: "Tom Smith"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: biomasslmb.json
vignette: >
  %\VignetteIndexEntry{Correlation Profiling Proteomics with DIA-NN: Part 1 - Data Processing and QC}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

Correlation profiling, also known as protein correlation profiling (PCP), is a powerful approach for subcellular proteomics that enables the study of protein localisation and organelle composition. In a typical correlation profiling experiment, cells are lysed and fractionated (e.g., by differential centrifugation), and the protein abundance profile across fractions is measured. Proteins that co-localise will show similar abundance profiles across the fractions.

Data-Independent Acquisition (DIA) is well-suited to correlation profiling experiments because:

1. It provides more consistent quantification across samples than Data-Dependent Acquisition (DDA)
2. It typically has fewer missing values than DDA
3. It can provide deep proteome coverage with good quantitative accuracy

In this notebook, we will cover the data processing and quality control steps for DIA data generated by DIA-NN, following the workflow described in the appendix of the F1000Research article on correlation profiling proteomics.

## Learning objectives

By the end of this notebook, you will be able to:

- Read in and understand DIA-NN output files
- Apply appropriate FDR filtering
- Perform quality control on DIA data
- Filter and normalise precursor/peptide-level data
- Summarise to protein-level abundances
- Understand the specific considerations for correlation profiling experiments

# Load required packages

To clarify which functionality is provided by which package, we will use `package::function`. For your own code, there is no need to specify the package unless you want to maintain this clarity.

```{r, message=FALSE}
library(QFeatures)
library(biomasslmb)
library(ggplot2)
library(tidyr)
library(dplyr)
```

# Defining the contaminant proteins

We need to remove contaminant proteins. These are defined using the cRAP (common Repository of Adventitious Proteins) database. Below, we parse the contaminants fasta to extract the IDs for the proteins in both 'cRAP' format and Uniprot IDs.

```{r}
crap_fasta_inf <- system.file(
  "extdata", "cRAP_20190401.fasta.gz", 
  package = "biomasslmb"
)

# Extract the protein IDs associated with each cRAP protein
crap_accessions <- biomasslmb::get_crap_fasta_accessions(crap_fasta_inf)

print(head(crap_accessions))
```

# Understanding DIA-NN output

DIA-NN produces several output files. The main files are:

- **report.tsv**: Contains all precursor-level information with Q-values for each run
- **report.pr_matrix.tsv**: Precursor-level quantification matrix (already FDR filtered)
- **report.pg_matrix.tsv**: Protein group-level quantification matrix

For correlation profiling, we typically want fine-grained control over the FDR filtering, so we start with the `report.tsv` file.

# Read in input data

We start by reading in quantitative proteomics data into a `QFeatures` object, which is the standard Bioconductor object for holding quantitative proteomics data. See [here](https://www.bioconductor.org/packages/release/bioc/html/QFeatures.html) for documentation about the `QFeatures` object. 

Here, we will use the `biomasslmb::readDIANNFilterQJoin` function, which allows us to control the FDR thresholds for the precursor and protein (run-specific and global). This function reads in the `report.tsv` file from DIA-NN and performs the following:

1. Reads the data into separate `SummarizedExperiment` objects for each run
2. Filters based on Q-values
3. Joins the data across runs

If you are happy with the filtering settings in DIA-NN, you can directly read the `report.pr_matrix.tsv` into a `QFeatures` object using the `QFeatures::readQFeatures` function.

For this example, we use the `diann_report.tsv` file available from the `biomasslmb` package. This is a truncated file containing the precursors for 500 proteins.

```{r}
diann_report_inf <- system.file(
  "extdata", "diann_report.tsv", 
  package = "biomasslmb"
)

dia_qf <- readDIANNFilterQJoin(diann_report_inf,
                               global_protein_q = 0.01,
                               run_protein_q = 0.01,
                               run_precursor_q = 0.01)
```

Let's examine the structure of the QFeatures object:

```{r}
dia_qf
```

## Question 1

**What FDR thresholds have been applied to the data? Why might you want to use different thresholds for global protein FDR vs run-specific protein FDR?**

<details>
<summary>Click to reveal answer</summary>

The thresholds applied are:
- Global protein FDR: 1% (`global_protein_q = 0.01`)
- Run-specific protein FDR: 1% (`run_protein_q = 0.01`)
- Run-specific precursor FDR: 1% (`run_precursor_q = 0.01`)

You might want to use different thresholds because:

1. **Global protein FDR** ensures that across all runs combined, only 1% of protein identifications are expected to be false positives. This is important for overall data quality.

2. **Run-specific protein FDR** controls the false positive rate within each individual run. You might want a more stringent threshold here if some runs have lower quality data.

3. For correlation profiling specifically, you may want consistent protein identification across fractions, which could justify using more lenient thresholds in individual runs while keeping the global FDR strict.

</details>

## Handling zero values

Mass spectrometry cannot assert that a protein has exactly zero abundance - rather, it may be below the detection limit. Zero values should be treated as missing data.

```{r}
# Check for zero values
n_zeros <- sum(assay(dia_qf[['peptides_fdr_cntrl']]) == 0, na.rm = TRUE)
message(sprintf("Number of zero values: %d", n_zeros))

# Replace zeros with NA
dia_qf[['peptides_fdr_cntrl']] <- QFeatures::zeroIsNA(dia_qf[['peptides_fdr_cntrl']])
```

## Update sample names

The sample names may include redundant information that we can remove for clarity.

```{r}
# Inspect current column names
colnames(dia_qf)[["peptides_fdr_cntrl"]]
```

```{r}
# Remove redundant prefixes from column names
colnames(dia_qf)[["peptides_fdr_cntrl"]] <- gsub('HYE_DIA_', '', 
                                                  colnames(dia_qf)[["peptides_fdr_cntrl"]])
dia_qf <- renamePrimary(dia_qf, colnames(dia_qf)[["peptides_fdr_cntrl"]])

# Check updated names
colnames(dia_qf)[["peptides_fdr_cntrl"]]
```

## Setting up experimental metadata (colData)

For correlation profiling experiments, the experimental metadata typically includes information about the fractions. In this example dataset, we'll create a simple experimental design from the sample names.

```{r}
# Check current colData - it's empty
data.frame(colData(dia_qf))
```

```{r}
# Create colData from sample names
# In a real correlation profiling experiment, this would include fraction information
colData(dia_qf) <- data.frame(quantCols = rownames(colData(dia_qf))) %>%
  separate(quantCols, sep = '', into = c(NA, 'condition', 'replicate'), remove = FALSE) %>%
  tibble::column_to_rownames('quantCols')

data.frame(colData(dia_qf))
```

```{r}
# Add colData to the peptide-level assay
colData(dia_qf[['peptides_fdr_cntrl']]) <- colData(dia_qf)
```

## Question 2

**For a correlation profiling experiment with 6 fractions and 3 biological replicates, how would you structure the colData? Write code to create an appropriate experimental design data frame.**

<details>
<summary>Click to reveal answer</summary>

```{r, eval=FALSE}
# Example colData structure for correlation profiling
# 6 fractions x 3 replicates = 18 samples

exp_design_cp <- data.frame(
  sample_name = paste0("F", rep(1:6, 3), "_R", rep(1:3, each = 6)),
  fraction = rep(1:6, 3),
  replicate = rep(1:3, each = 6)
)

# The fractions might correspond to different centrifugation speeds/times
# You could add additional annotation:
exp_design_cp$fraction_description <- rep(
  c("1k_pellet", "3k_pellet", "6k_pellet", 
    "12k_pellet", "80k_pellet", "cytosol"), 
  3
)

print(exp_design_cp)
```

For correlation profiling, it's crucial that the fraction order is preserved and clearly annotated, as the correlation calculations depend on the relative abundance patterns across fractions.

</details>

# Filter peptides

We perform routine filtering to remove peptides that:

1. Could originate from contaminants
2. Don't have a unique master protein
3. Don't have any quantification values

```{r}
dia_qf[['peptides_filtered']] <- biomasslmb::filter_features_diann(
  dia_qf[['peptides_fdr_cntrl']], 
  contaminant_proteins = crap_accessions
)
```

# Quality control: Normalisation check

For correlation profiling, normalisation is particularly important because we need to compare abundance profiles across fractions. By default, DIA-NN performs normalisation. However, we should check whether this is appropriate for our experimental design.

**Important consideration for correlation profiling:** Global normalisation (like median normalisation) may not be appropriate if different fractions genuinely have different total protein amounts. In some correlation profiling designs, samples are loaded based on equal cell equivalents rather than equal protein amounts.

```{r, warning=FALSE, fig.show='hold', fig.width=7, fig.height=5, out.width="75%"}
# Plot the peptide-level quantification distributions per sample
biomasslmb::plot_quant(dia_qf[['peptides_filtered']],
                       log2transform = TRUE,
                       method = 'density') +
  theme_biomasslmb() +
  xlab('Peptide abundance (log2)')
```

## Question 3

**Look at the distribution plot above. Are the samples well normalised? What would indicate a problem that needs to be addressed?**

<details>
<summary>Click to reveal answer</summary>

When examining the distribution plot, you should look for:

1. **Similar peak locations**: The peaks of the density curves should be approximately aligned if the samples are well normalised.

2. **Similar distribution shapes**: The curves should have similar shapes (width, skewness) if the samples have similar quality.

**Warning signs that might indicate problems:**

- **Shifted peaks**: One or more samples with peaks shifted left or right might indicate loading differences or technical issues
- **Different widths**: Broader distributions might indicate higher variability or lower quality
- **Bimodal distributions**: Could indicate contamination or mixing issues
- **Very different total signal**: If some samples have much lower signal overall

**For correlation profiling specifically:**
If normalisation has been applied but the distributions still look different, this could be biologically meaningful (e.g., some fractions naturally contain more protein) or could indicate a technical problem. You should consider whether equal loading or equal cell equivalents was used when preparing the samples.

</details>

# Examining missing values

Missing values are a key consideration for DIA data and especially for correlation profiling, where we need consistent quantification across all fractions to calculate meaningful correlations.

```{r}
# Examine missing values per sample
nNA(dia_qf[['peptides_filtered']])$nNAcols %>%
  data.frame() %>% 
  knitr::kable(digits = 2)
```

```{r, fig.height=6, fig.width=8}
# Visualise missing value patterns
plot_missing_upset(dia_qf, i = 'peptides_filtered')
```

## Question 4

**Why are missing values particularly problematic for correlation profiling? What strategies might you use to handle them?**

<details>
<summary>Click to reveal answer</summary>

**Why missing values are problematic for correlation profiling:**

1. **Correlation calculation**: Pearson or Spearman correlations require values in all fractions. Missing values reduce the number of fractions available for correlation calculation, reducing statistical power.

2. **Profile distortion**: If a protein is missing in certain fractions but not others, it's unclear whether this represents a true absence or technical limitation.

3. **Systematic bias**: If missing values correlate with abundance (e.g., low-abundance proteins more likely to be missing), this can bias localisation predictions.

**Strategies to handle missing values:**

1. **Stringent filtering**: Remove proteins with too many missing values across fractions. For correlation profiling, you might require quantification in all or most fractions.

2. **Imputation**: 
   - Minimum value imputation: Replace NA with the minimum observed value (assumes missing = below detection)
   - K-nearest neighbours (KNN) imputation
   - Note: Imputation can introduce artefacts in correlation profiles

3. **Per-replicate analysis**: Calculate correlations within complete replicate sets, then combine results.

4. **Require complete cases**: Only use proteins quantified in all fractions (most conservative but safest for correlation analysis).

5. **Fraction-aware filtering**: For correlation profiling, consider whether a protein needs to be present in ALL fractions or just a minimum number (e.g., at least 4 of 6 fractions).

</details>

# Summarising to protein-level abundances

For correlation profiling, we typically work at the protein level. We'll use robust summarisation which can handle some missing values.

## Filtering by missing values

First, we filter peptides with too many missing values. For correlation profiling, we need to be more stringent than typical experiments because we need consistent quantification across fractions.

```{r}
# Filter peptides with more than 4/6 missing values
dia_qf[['peptides_filtered_missing']] <- QFeatures::filterNA(
  dia_qf[['peptides_filtered']], pNA = 4/6)

biomasslmb:::message_parse(rowData(dia_qf[['peptides_filtered_missing']]),
                           'Protein.Group',
                           "Removing peptides with > 4/6 missing values")
```

## Filtering by peptides per protein

We require at least 2 peptides per protein for reliable quantification.

```{r}
min_peptides <- 2

dia_qf[['peptides_filtered_forRobust']] <- biomasslmb::filter_features_per_protein(
  dia_qf[['peptides_filtered_missing']], 
  min_features = min_peptides, 
  master_protein_col = 'Protein.Group')

biomasslmb:::message_parse(rowData(dia_qf[['peptides_filtered_forRobust']]),
                           'Protein.Group',
                           "Removing peptides for proteins with < 2 peptides")
```

## Performing robust summarisation

```{r}
# Aggregate to protein-level abundances
dia_qf <- QFeatures::aggregateFeatures(
  dia_qf, 
  i = "peptides_filtered_forRobust", 
  fcol = "Protein.Group",
  name = "protein",
  fun = MsCoreUtils::robustSummary,
  maxit = 10000  # ensure sufficient iterations for convergence
)

biomasslmb:::message_parse(rowData(dia_qf[['protein']]),
                           'Protein.Group',
                           "Summarised to proteins")
```

## Masking protein quantifications with insufficient peptide support

Even though we required 2 peptides per protein overall, some individual samples might have protein abundances derived from only 1 peptide. We mask these.

```{r, fig.height=5, fig.width=5, out.width='50%'}
protein_retain_mask <- biomasslmb::get_protein_no_quant_mask(
  dia_qf[['peptides_filtered_forRobust']], 
  min_features = 2, 
  plot = TRUE, 
  master_protein_col = 'Protein.Group'
) 

dia_qf[['protein']] <- biomasslmb::mask_protein_level_quant(
  dia_qf[['protein']], 
  protein_retain_mask
)
```

# Quality control at protein level

## Missing values

```{r, fig.height=6, fig.width=8}
# Check missing values at protein level
nNA(dia_qf[['protein']])$nNAcols %>%
  data.frame() %>% 
  knitr::kable(digits = 2)

plot_missing_upset(dia_qf, i = 'protein')
```

## Question 5

**After summarisation, what percentage of missing values do you have at the protein level? For a correlation profiling experiment with 6 fractions, what is the maximum number of missing values you would accept per protein? Why?**

<details>
<summary>Click to reveal answer</summary>

```{r}
# Calculate the percentage of missing values
pct_missing <- round(nNA(dia_qf[['protein']])$nNA$pNA * 100, 2)
message(sprintf("Percentage of missing values at protein level: %s%%", pct_missing))
```

**For correlation profiling with 6 fractions:**

The choice of maximum missing values depends on your analysis approach:

1. **Strict approach (0 missing)**: If you want to calculate correlations across all 6 fractions, you need complete data. This gives the most reliable correlations but may exclude many proteins.

2. **Moderate approach (1-2 missing)**: You could calculate correlations on 4-5 fractions. This includes more proteins but correlations may be less reliable.

3. **Lenient approach (3 missing)**: With only 3 values, correlation calculations become unreliable and should generally be avoided.

**Recommended for correlation profiling**: 
- Require at least 4-5 of 6 fractions to have values
- Consider whether the missing values are random or systematic (e.g., always missing in certain fractions might indicate true localisation)

</details>

# Inspecting data retention through processing

Let's visualise how many peptides and proteins were retained at each processing step.

## Peptides/Precursors retained

```{r, fig.height=7, fig.width=7, fig.fullwidth=TRUE, out.width='75%'}
rename_cols <- c(
  'Peptides passing FDR thresholds' = 'peptides_fdr_cntrl',
  'Quantified, contaminants removed' = 'peptides_filtered',
  '<= 4/6 missing values' = 'peptides_filtered_missing',
  '>1 peptides per protein' = 'peptides_filtered_forRobust'
)

rowvars <- c('Precursor.Id')

samples_present <- get_samples_present(dia_qf[,,unname(rename_cols)], rowvars, rename_cols)
plot_samples_present(samples_present, rowvars, breaks = seq(2, 10, 2)) + 
  ylab('Precursor')
```

## Proteins retained

```{r, fig.height=7, fig.width=7, fig.fullwidth=TRUE, out.width='75%'}
rename_cols_prot <- c(rename_cols, 'Protein' = 'protein')

rowvars_prot <- c('Protein.Group')

samples_present <- get_samples_present(dia_qf, rowvars_prot, rename_cols_prot)
plot_samples_present(samples_present, rowvars_prot, breaks = seq(2, 10, 2))
```

# Correlation profiling QC: Sample correlation

For correlation profiling, we expect samples from the same fraction (across replicates) to correlate highly with each other. Let's check this.

```{r, fig.width=7, fig.height=7, out.width="75%"}
# Plot sample correlation heatmap
plot_cor_samples(dia_qf, 'protein')
```

## Question 6

**What pattern would you expect to see in a sample correlation heatmap for a successful correlation profiling experiment with 3 biological replicates of 6 fractions?**

<details>
<summary>Click to reveal answer</summary>

For a successful correlation profiling experiment, you would expect:

1. **High correlation within fractions**: Replicates of the same fraction should have the highest correlations (close to 1.0), forming blocks along the diagonal if samples are ordered by fraction.

2. **Variable correlation between fractions**: Adjacent fractions (e.g., consecutive centrifugation steps) might show moderate correlation, while very different fractions (e.g., nuclear vs cytosolic) should show lower correlation.

3. **Consistent patterns across replicates**: The pattern of correlations between fractions should be similar for each biological replicate.

**Warning signs:**

- A replicate that doesn't cluster with its corresponding fractions → possible sample mix-up or technical failure
- One fraction correlating poorly with itself across replicates → technical issues with that fraction
- All samples having very similar correlations → may indicate poor fractionation or very different total loading

</details>

# PCA visualisation

Principal Component Analysis can help visualise how samples group and whether the fractionation was successful.

```{r, fig.width=7, fig.height=6, out.width="75%"}
# PCA plot
plot_pca(dia_qf, 
         i = 'protein', 
         colour_by = 'condition') +
  ggtitle("PCA of protein abundances")
```

## Question 7

**In a well-designed correlation profiling experiment, what would you expect the PCA to show? What would be concerning?**

<details>
<summary>Click to reveal answer</summary>

**Expected results:**

1. **Separation by fraction**: PC1 or PC2 should separate samples by fraction, indicating that the fractionation procedure created distinct proteome profiles.

2. **Replicate clustering**: Biological replicates of the same fraction should cluster together, indicating good reproducibility.

3. **Ordered progression**: Fractions might show an ordered progression along a PC, reflecting the sequential nature of differential centrifugation.

**Concerning results:**

- **Replicates not clustering**: If replicates of the same fraction are scattered, this suggests poor reproducibility
- **No separation by fraction**: If all fractions cluster together, the fractionation may not have worked
- **Batch effects dominating**: If samples separate by replicate rather than fraction, batch effects may be confounding the data
- **Outlier samples**: A single sample far from others might indicate a failed sample or sample swap

</details>

# Save processed data

```{r, include = FALSE}
# Save file to package as data so it can be read back in the correlation analysis vignette
usethis::use_data(dia_qf, overwrite = TRUE)
```

# Summary

In this notebook, we have:

1. **Read DIA-NN data** using `readDIANNFilterQJoin()` with appropriate FDR thresholds
2. **Handled missing values** by replacing zeros with NA
3. **Set up experimental metadata** in the colData
4. **Filtered peptides** to remove contaminants and ensure protein uniqueness
5. **Checked normalisation** using density plots
6. **Examined missing values** and their patterns
7. **Summarised to protein level** using robust summarisation
8. **Performed QC** using correlation heatmaps and PCA

## Key considerations for correlation profiling

1. **FDR thresholds**: Consider using consistent thresholds across runs to avoid systematic differences
2. **Normalisation**: Be careful with global normalisation if fractions have genuinely different protein amounts
3. **Missing values**: More stringent filtering may be needed to ensure reliable correlation calculations
4. **Quality control**: Check that replicates of the same fraction correlate highly

In the next notebook, we will perform the actual correlation profiling analysis to predict protein localisations.

# Session info

```{r}
sessionInfo()
```
